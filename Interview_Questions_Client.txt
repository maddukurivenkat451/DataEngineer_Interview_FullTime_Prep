**********Client 1 Interview questions for Data Engineer****************

Explain me about your self and latest project

Explain me about working with AWS cloud services and how do you leverage them.

How often do S3 lifecycle rules run?

What is retention period in S3 bucket?

What is the lifecycle of object stored in S3?

Spark optimizations techniques

SPARK Cache vs Persit and how it gonna be used

Explain about ETL Pipelne you built in PYSPARK.

Group By key Vs Reduce By key

Explain Spark SQL and it's advantages

Difference between JSON file and Dictonary

How unit testing has been done in your pipeline

Have you done any regression testing if yes how?

Have you used Airflow and which operators are used?

How do you manage code repository ? Git or Bit bucket?

How CI/CD pipe line has been built in your current project?

Sql joins (Left, Right, Inner, Full, Left semi) and explain

How do you optimize the sql queries when a stored procedure is running?

Types of window analytical functions

Difference between Rank and Dense Rank and RowNumber

Have you used windows analytical functions in Spark if yes how it has been used?

Difference between Roles and policies in AWS?

Difference between delta and parquet format

Snowflake vs Redshift difference

How do you Manage Airflow? Is it EC2 manged or Aws Managed MWFAA?

*************************Client 2****************
1) situations where you had challenging parts in pipeline development
2) Things to consider while building a datalake and migrate data from old to new enviroment?
3) Spark performance tuning and what are the latest enhancements were done in Spark 3.
4) Have you written any UDFS in pysaprk if yes please explain.
5) If you have 100 tables instaed of getting them sequentially i need to pull parallely How can you do that with spark?
6) Sql questions all joins(inner, leftouter, Right Outer, left semi ,left anti) and explain 
7) Difference between windowing and grouping in sql
8) CTE in sql what is the use
9) CDC process in spark
10) Have you heard about the Delta tables if yes please explain advantages
11) Airflow how you used in your projects and advantages
12) Explain How many types of SCD in datawarehouse 
13) How do you deploy your applications using Databricks ?
14) What is your CICD process ?
15) How did you create server less applications in Databricks ?
16) how do you go test data ingested from source systems against target systems?
17) How do you handle conflicts with business teams on deliveries ?


Coding: Python

1) Given input (12th Mar 2017) expecting the output (12-03-2017) to get date and year and month with out using inbulit libraries. write python program
2) Given input = sam bob and expecting output= "Sam Bob" write python program
3) Write pyspark program to skip followed by number Input= 1,3,5,7,6,4,5and output = 1,5,6,5
4) Given input = (2018 03 27) and expecting to get max days on a particular month suppose Jan has 31 days, Feb has 28 days and leap year has 29 days, March has 30 days
5) Given input a nested json file and asked to read in a dataframe and show the data
6) 135 = 1**1+3**2+5**3? (Need to raise power If 75 need to 7 power 1 plus 5 power 2 will be false but 135 is true)
7) Remove duplicates from table which has multiple email id's for an employee. keep the shortest email per employee.

More questions:

1) gave two data frames employee and salary. Write code where we build a dataftame with employee name, dept and level column where level column should be high or low if salary > 1000 or < 1000 respectively.
2) gave a text file and write spark code to read data and write to a df


***************Client 3*********

Spark optimizations techniques

SPARK Cache vs Persit and how it gonna be used

Explain about ETL Pipelne you built in PYSPARK.

Group By key Vs Reduce By key

Explain Spark SQL and it's advantages

How do you debug when spark job fails

Spark broadcasting and what is the use when to use indepth

Have you used delta lake and what is the advantages

Types of window analytical functions

Difference between Rank and Dense Rank and RowNumber

Have you used windows analytical functions in Spark if yes how it has been used?

Vaccum in delta tables

Have you ever used SCD 2 and explain me it's usage and how it has been implemented

How do you implemented CDC in spark

Difference between Snowflake schema vd start schame vs Galaxy schema in Datawarehouse and its advantages

How do you interact with prodcut team on requirements

Explain Timetravel concept in Delta lake

DElta tables advantages

what is snowpipe

what is snowpark and advantages?

explain Kafka Architecture

Explain various types of data models?
Conceptual,Logical and Physical


***************Client 4*********
Question 1:
5 columns 1 row
transform to 5 rows 1 col
Ans: transpose
df.groupBy().pivot("id").agg(F.first(F.col("id"))).show()


employee 
name 	place 	timestamp
a     newyork   when transferred to ny
a	california	some new date

with test as(
select *,rank() over(patition by date) from employee)
select * from test where rank = 1


1. What is EMR Cluster? and about Kerberos?
2. Behavioural questions realted to product owner? how do you manage work!

***************Client 5*********

1) Introduction, work experience.
2) About latest project, use case, any lead experience with most of data engineer responsibilites.
3) Databricks and AWS experience

Approach for spark performance optimizations
Spark config options used, and what situations they are used?
How joins work in spark joins, like sort merge join.

avro vs parquet (multiple file formats)
coalesce vs repartition
Databricks scheduler vs Airflow scheduler
how to call functions from other classes in the python file while spark submit.
broadcast joins
How to handle the incremental data?
Data volumes processed
Real work env issues faced
Data validations, how implemented in project?
Coding Standards and practices from prev projects.

***************Client 6*********


1) Explain Spark experience and Databricks Run time version

2) Optimization of the spark query execution.

3) Explain Spark driver and executors? How do You define the memory configurations?

4) What kind of transformations worked on?

5) How do You attach external libraries to the cluster?

6) How do you Mask sensitive information via spark? Explain scenario

7) Data validation and Data Quality tools?

8) Explain about various joins in Spark and Sql?

9) How do defined the partitions in a topic and how many executors needed to read the data from topic in parallel?

10) Explain various cluster types in Databricks AWS ? How do You choose which cluster is suitable for your job?

11) Pyspark Window functions?

12) How do you read Sql Server tables in Databricks and pre steps to take explain step by step

13) How do you ready one databricks note book from another data bricks note book

14) Explain Delta table and benefits of it 

15) Time Travel concept in Delta and how it has been used in current project

16) How are you handling Updates and deletes from Sql server

17) Star schema vs snowflake schema vs galaxy schema

18) What are late arriving dimensions

19) Dimension vs Fact Table

20) Explain concept if widgets in databricks

21) How how do you read json file in ADLS and get in to a structure format?

What is meant by OLTP vs OLAP database?
What tool have you used for data modelling?
What is a confirmed Dimension?
give an example of a data model you have created
Look at this data model and tell me what do you make sense of it?
how to get the data for date of latest trans of cust considering the customer status
have you used CTAS - write example to remove dupicates with CTAS?
what is meant by the grain of a fact table?
How do you determine the grain of the fact table?
How do you go about designing a CDC data model?
You gave the concept of SCD1 and SCD2, but how do you design the change data capture ?
What is the difference between a regular view and a materialized view?
When do you use a regular view?
What is the difference between a star and snowflake schema , which is more complex?
Will star schema have more joins or snowflake schema ?
If you have to join more than one fact table - what comes to your mind first?
how do you do performance tuning of a database?
if you have billions of rows how do you design such tables or data model? Indexes? no Add partitions
have you used clustering and bucketing? what is the purpose of bucketing ?
What is the difference between the row based database and columnar database?
Which gives more compression, row based or columnar and why?
What is a data mesh Architecture?
what is a lamda function in python?
what is list comprehension?
have you used Broadcasting technique in spark and what is the use of it?
have you used Snowpipe?
what are different layers of caching in snowflake?


SQL
----

1) There are employee and department tables. department id is the common column in both the tables. How do You find employee in each department whose salary is maximum.

