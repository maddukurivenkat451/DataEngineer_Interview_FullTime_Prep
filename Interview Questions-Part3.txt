
******************************************************
************
1) DBT
2) Snowflake 
3) Airflow
*******************************************************

############DBT ############


what is a DBT model?

What are sources in DBT?

How do you create a DBT model?

How does DBT handle dependencies betwen models?

what is the difference between dbt core and dbt cloud?

Can you explain the difference between ‘ref’ and ‘source’ in DBT?

What is the difference between ref() and source() in dbt? When should you use each?

How do you run DBT models, and what key DBT commands are used in projects?

What is the role of the dbt_project.yml file, and why is it important?

What is the role of the profiles.yml file in dbt, and how does it manage connections to different environments?

What are DBT macros, and how do they enhance SQL functionality in DBT?

What is Metric and Metric Flow in DBT?

How would you define a macro in dbt, and what is the syntax for creating one? Can you provide an example of a simple macro and explain how you would use it within a dbt model?

Can you explain how Jinja works within macros and give an example where you would use a Jinja template to dynamically generate SQL code based on input parameters?

What is package in dbt?Explain advantages of using Packages in DBT? What are the packages available in DBT?

How can DBT be used to handle incremental data loads?

How does dbt handle schema migrations?

What are the different types of dbt hooks, and when would you use them?

How does dbt handle incremental models? What are the key configurations required to implement them?

What is the purpose of the dbt test command, and how can you write custom tests for your models?

How does DBT handle testing of data models, and what are the different types of tests?

How does DBT manage version control and collaboration in data projects?

How do you use Jinja to improve sql code in DBT?

Define are the four types of materializations in DBT?

How do you create custom materialization in dbt?

What are ephemeral models in DBT?

How can you debug your DBT models? Tell me about two ways?

Explain semantic layer architecture in DBT? Adavntages of using it?

Explain how you’ve optimized complex DBT models to improve performance. What techniques do you use to minimize run times when dealing with large datasets?

How do you handle dependency management in DBT in a project with hundreds of models? What strategies do you implement to ensure a smooth dependency graph?

How do you manage dbt deployment accross multiple environments (dev, stg and prod)?

How do you use DBT's ref() function, and what common pitfalls have you encountered when defining relationships between models?

What are some best practices you follow when implementing DBT hooks to ensure they don't introduce unnecessary complexity or performance issues? Are there any limitations or pitfalls to watch out for when using hooks in DBT?

You need to run a data quality check every time a DBT model finishes execution to ensure data completeness and integrity. How would you implement this using a post-hook, and what kind of checks might you include?

Can you explain what DBT hooks are and provide examples of scenarios where you would use pre-hook and post-hook in your data pipeline?
 
After executing a DBT model, you want to run a query that checks whether the data meets certain conditions (e.g., no null values in a critical column). How would you implement this logic using a post-hook in DBT?

Can you explain the role of dbt run, dbt test, and dbt seed in your workflow? How do you automate these tasks in a CI/CD pipeline?

How do you manage data freshness and handle incremental models in DBT? Can you describe a specific use case where an incremental model improved your ETL process?

Describe a challenging debugging scenario you encountered in DBT. How did you identify and resolve the issue, especially with regard to model dependencies or data lineage?

How do you approach testing in DBT? Can you explain how you set up custom tests using schema and data tests to ensure data quality?

How do you use Jinja in DBT for dynamic SQL generation? Can you give an example of how you’ve used macros to create reusable SQL code blocks?

You’re tasked with ensuring high data quality in a dbt-based pipeline. How would you implement data quality checks within your dbt models, and how would you handle situations where a test fails?

A business team has reported that some dbt models are taking longer than expected to run, and the overall performance of the data pipeline is degrading. How would you approach identifying performance bottlenecks, and what specific dbt techniques or strategies would you use to optimize the performance of the models?

Resources to prepare:

https://snowflakemasters.in/dbt-interview-questions/


################SNOWFLAKE ############


What are the features of Snowflake? 

What is the schema in Snowflake?

What kind of SQL does Snowflake use?

What ETL tools do you use with Snowflake?

What type of database is Snowflake?

What is Snowflake Time Travel?

What do you know about the failsafe in Snowflake?

Why fail-safe instead of Backup?

What is SnowPipe?

What is Data Retention Period in Snowflake?

What is “Stage” in Snowflake?

Is Snowflake OLTP or OLAP?

What makes Snowflake so fast?

How to create a Snowflake task?

Explain Horizontal and Vertical Scaling in SNOWFLAKE?

What is Auto-scaling in Snowflake?

How is Snowflake different from Redshift?

What do you mean by zero-copy cloning in Snowflake Explain the commands?

How Does Snowflake Differ from AWS?

How is metadata stored in Snowflake?

Can you store encrypted data in Snowflake?

How data is secured in Snowflake?

Explain the data compression in Snowflake?

What is Materialized view in Snowflake?

Name a few advantages that arise out of data compression in Snowflake?

What is Snowflake Caching?

What are the advantages of Snowflake Schema?

Explain Snowflake streams and tasks?

Explain dynamic masking of data in snowflake? How do you apply row level and column level masking?

How to optimize or improve query performance in Snowflake?

Explain Snowflake's pricing model.

What is Snowflake & How it is different than On prem Data warehouses

Explain the Snowflake Architecture or How Snowflake Compute & Storage separate Architecture help us

What are the type of caching available in Snowflake, How would you identify if your query is returning result from Query Cache/ Metadata cache or VW cache

What are common types of Tables we have in Snowflake

Can you explain, when would you prefer Transient tables over Permanent Table in Snowflake

How does Snowflake handle data storage & Processing

What is Snowflake Stages & When would you use which Stage

Why Cloning in Snowflake known as Zero copy clone

What is Time Travel and How it works under the hood

What is the role of virtual warehouses in Snowflake, and how do they affect performance?

What are the limitation of Materialized views we have in Snowflake

Can you explain the Query Execution flow in Snowflake

What is Scale up vs Scale out in Snowflake

How Snowflake processes queries using micro-partitions

What are the size range of Micro Partition in Snowflake

How would you choose the perfect size of Virtual warehouse for your requirement

How can we Optimize the Storage & Compute cost in Snowflake

Suppose you have given a requirement to migrate the Data from On prem to Snowflake, What all check you will perform

What is the difference between Clustering vs Search Optimization Service , Where you will use SOS over Clustering

How do you troubleshoot and optimize the slow running queries in Snowflake

Write a query to find out if this table is being used in any View definition or not

How would you implement SCD type 2 in Snowflake

My client is giving me files in date wise folder in AWS S3 bucket, You need to implement this COPY activity in such a way that it should pick the file from current date folder and load in Snowflake

I have one Parquet file in AWS s3 bucket, Now create table for that file without checking the Stage files

How do you Integrate S3,ADLS or GCS with Snowflake? If i integrate AWS S3 with Access keys then will you face any challenges?

How do you Integrate S3 with Snowflake? If i integrate AWS S3 with Access keys then will you face any challenges?

What is the concept of micro-partitioning in Snowflake?

Can you explain the difference between Snowflake's virtual warehouse and database?

How do Snowflake's scaling and auto-suspend features work?

What is the difference between Snowflake's transient and permanent tables?

How does Snowflake handle data sharing between different accounts?

What are Snowflake stages and how do they work?

What is the role of Snowflake’s Data Exchange?

How does Snowflake ensure data security, and what features does it offer?

You need to store sensitive customer data in Snowflake. What steps would you take to ensure compliance with data protection regulations?

What are Snowflake roles and how is access control managed?

How do you optimize Snowflake queries for performance?

What is the Snowflake's data loading process? How do you load data from different file formats (e.g., CSV, Parquet)?

Can you explain Snowflake's time travel feature and its use cases?

How does Snowflake handle semi-structured data (JSON, Avro, Parquet)?

What are Snowflake streams and tasks, and how are they used for data processing?

How do you implement real-time analytics using Snowflake. How would you design a pipeline to support this?

What is the purpose of clustering in Snowflake, and how does it work?

How does Snowflake handle failover and disaster recovery?

What are some common performance issues in Snowflake, and how can they be addressed?
What is the role of Snowflake's external tables?
How do you troubleshoot and resolve query performance issues in Snowflake?
Can you explain the difference between Snowflake and traditional OLTP databases?
How do you manage Snowflake data warehouse lifecycle and storage?
What are Snowflake’s best practices for data modeling?
What is a Snowflake schema and how does it differ from a star schema?
How do you implement ETL processes in Snowflake?
What are Snowflake's capabilities regarding data governance and auditing?
How would you migrate data from an on-premises data warehouse to Snowflake?
How can you mask dynamically PHI or PII data in snowflake and what is the process?

I want to restrict viewing data for few users only how to do that in snowflake?


Snowflake Interview Questions:

https://skphd.medium.com/snowflake-interview-questions-and-answers-part-2-1c1ddeb1f300


############ AIRFLOW ############

What is Airflow?

What issues does Airflow resolve?

Explain how workflow is designed in Airflow?

How do we Instantiate a DAG?

How do we Importing Modules in Airflow?

How can we delete a DAG?

What are the types of Executors in Airflow?

What are the pros and cons of SequentialExecutor?

What are the pros and cons of LocalExecutor?

What are the pros and cons of CeleryExecutor?

What are the pros and cons of KubernetesExecutor?

How to define a workflow in Airflow?

How do you make the module available to airflow if you're using Docker Compose?

How to start scheduler DAG in Airflow?

Default database in Airflow

What is XComs In Airflow?

What is xcom_pull in XCom Airflow?

Explain how XComs work in Airflow and give an example of how you would use them to pass data between tasks in a DAG. What are some limitations or potential pitfalls of using XComs?

What is Jinja templates?

How to use Airflow XComs in templates?

What is sensor in airflow and use of it?

What is Macros?

Default timezone used to schedule in airflow dags.

what is operator in airflow.

How do you write a custom operator in Airflow?

What is Dagrun_timeout?

What is catch up in airflow?

What is hook in Airflow?

What is dummy operator?

How do I submit spark jobs to EMR cluster from Airflow?

How do you create an EMR cluster in Airflow?

What is celery in Airflow?

What is flower in Airflow?

Can we create a single node cluster using EMR?

How do you schedule a DAG to run at a specific interval in Airflow?

What are advantages and disadvantages of AIRFLOW?

What are the limitations in Airflow?

How do you make the module available to airflow if you're using Docker Compose?

How do you schedule a DAG to run at a specific interval in Airflow?

How can you trigger DAGs in Airflow, and what are the different ways to do so?

How to control the parallelism or concurrency of tasks in Apache Airflow configuration?

What if your Apache Airflow DAG failed for the last ten days, and now you want to backfill those last ten days' data, but you don't need to run all the tasks of the dag to backfill the data?

What will happen if you set 'catchup=False' in the dag and 'latest_only = True' for some of the dag tasks?

How would you approach if you wanted to queue up multiple dags with order dependencies?

In Airflow, what happens if a task fails? How would you configure retry behavior, and what are the options for alerting the team if a task continues to fail after multiple retries?

You need to dynamically generate multiple tasks in an Airflow DAG based on a set of parameters or configurations (e.g., looping over a list of values). How would you handle dynamic DAG generation in Airflow? Can you provide an example?

Can you explain what an Airflow sensor is and how it differs from other operators? How do sensors work, and what is their purpose in a DAG?

If an Airflow sensor fails (for example, if the file it’s waiting for does not appear within the expected timeframe), how would you handle such failures? What are the options for retrying or alerting on sensor failures?

Can you describe some of the major features and improvements that were introduced in Airflow 2.8, especially regarding performance, UI, and security? How do these improvements enhance the user experience and DAG management?

Your team is currently using an older version of Airflow, and you are tasked with upgrading to Airflow 2.8. What steps would you take to ensure a smooth upgrade process? What are the key things to watch out for when migrating to Airflow 2.8?

Airflow 2.8 introduced enhancements to the TaskFlow API. Can you explain how the TaskFlow API works in Airflow 2.8 and provide an example of how you would use it to create Python-based tasks in a DAG? How does it improve task management compared to older versions?
